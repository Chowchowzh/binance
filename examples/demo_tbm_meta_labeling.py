#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‰åˆ†ç±»æ ‡ç­¾æ³• (TBM) å’Œå…ƒæ ‡ç­¾æŠ€æœ¯æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨é«˜çº§æœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æå‡äº¤æ˜“ä¿¡å·è´¨é‡ï¼š
1. ä¸‰åˆ†ç±»æ ‡ç­¾æ³•ï¼šä½¿ç”¨åŠ¨æ€è¾¹ç•Œç”Ÿæˆè·¯å¾„ä¾èµ–çš„æ ‡ç­¾
2. å…ƒæ ‡ç­¾æŠ€æœ¯ï¼šä¸¤é˜¶æ®µå­¦ä¹ æ¡†æ¶æå‡ä¿¡å·ç²¾åº¦
3. å¢å¼ºä¿¡å·ç”Ÿæˆï¼šç»“åˆä¸¤ç§æŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡äº¤æ˜“ä¿¡å·
4. å¼ºåŒ–å­¦ä¹ äº¤æ˜“ï¼šåŸºäºMDPçš„Actor-Criticäº¤æ˜“ç­–ç•¥

ä½¿ç”¨æ–¹æ³•ï¼š
    python demo_tbm_meta_labeling.py [--mode MODE] [--data_path PATH]
    
å‚æ•°ï¼š
    --mode: è¿è¡Œæ¨¡å¼ ('train', 'inference', 'demo', 'rl_demo', 'rl_train')
    --data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
"""

import sys
import os
import argparse
import warnings
import pandas as pd
import numpy as np
from datetime import datetime

# Add project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_processing.features.triple_barrier_labeling import TripleBarrierLabeler
from data_processing.features.advanced_features import AdvancedFeatureEngineer, add_advanced_features
from strategy.training.advanced_train_pipeline import AdvancedTrainingPipeline
from strategy.training.enhanced_signal_generator import EnhancedSignalGenerator
from strategy.analysis.advanced_model_evaluation import AdvancedModelEvaluator, comprehensive_model_evaluation
from config.settings import load_config

# å¼ºåŒ–å­¦ä¹ ç›¸å…³å¯¼å…¥
try:
    from strategy.reinforcement_learning.rl_training_pipeline import RLTrainingPipeline
    from strategy.reinforcement_learning.robust_backtester import RobustBacktester
    from strategy.reinforcement_learning.mdp_environment import TradingMDPEnvironment
    from strategy.reinforcement_learning.actor_critic_agent import ActorCriticAgent
    RL_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ å¼ºåŒ–å­¦ä¹ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    RL_AVAILABLE = False

warnings.filterwarnings('ignore')


def demo_tbm_labeling():
    """æ¼”ç¤ºä¸‰åˆ†ç±»æ ‡ç­¾æ³•çš„ä½¿ç”¨"""
    print("=" * 80)
    print("ğŸ¯ æ¼”ç¤º 1: ä¸‰åˆ†ç±»æ ‡ç­¾æ³• (Triple-Barrier Method)")
    print("=" * 80)
    
    # åˆ›å»ºç¤ºä¾‹ä»·æ ¼æ•°æ®
    np.random.seed(42)
    n_periods = 1000
    
    # æ¨¡æ‹Ÿä»·æ ¼éšæœºæ¸¸èµ°
    returns = np.random.normal(0.0001, 0.02, n_periods)
    prices = pd.Series(100 * np.exp(np.cumsum(returns)))
    
    print(f"åˆ›å»ºç¤ºä¾‹ä»·æ ¼æ•°æ®: {len(prices)} ä¸ªæ•°æ®ç‚¹")
    print(f"ä»·æ ¼èŒƒå›´: ${prices.min():.2f} - ${prices.max():.2f}")
    
    # åˆå§‹åŒ–TBMæ ‡ç­¾å™¨
    tbm_labeler = TripleBarrierLabeler(
        profit_factor=2.0,      # æ­¢ç›ˆå› å­
        loss_factor=1.0,        # æ­¢æŸå› å­
        volatility_window=20,   # æ³¢åŠ¨ç‡çª—å£
        max_holding_period=50,  # æœ€å¤§æŒä»“æœŸ
        min_return_threshold=0.001  # æœ€å°æ”¶ç›Šé˜ˆå€¼
    )
    
    # ç”ŸæˆTBMæ ‡ç­¾
    tbm_labels = tbm_labeler.generate_triple_barrier_labels(prices)
    
    # åˆ†ææ ‡ç­¾è´¨é‡
    quality_analysis = tbm_labeler.analyze_label_quality(tbm_labels)
    
    print(f"\nğŸ“Š TBMæ ‡ç­¾è´¨é‡åˆ†æ:")
    print(f"  - æ€»äº‹ä»¶æ•°: {quality_analysis['total_events']}")
    print(f"  - å¹³å‡æŒä»“æœŸ: {quality_analysis['holding_period_stats']['mean']:.2f} æœŸ")
    print(f"  - å¹³å‡æ”¶ç›Šç‡: {quality_analysis['return_stats']['mean']:.4f}")
    print(f"  - æ”¶ç›Šç‡æ ‡å‡†å·®: {quality_analysis['return_stats']['std']:.4f}")
    
    # æ˜¾ç¤ºå„ç±»æ ‡ç­¾çš„èƒœç‡
    for label in [-1, 0, 1]:
        if f'returns_label_{label}' in quality_analysis:
            stats = quality_analysis[f'returns_label_{label}']
            label_name = {-1: "æ­¢æŸ", 0: "æ—¶é—´åˆ°æœŸ", 1: "æ­¢ç›ˆ"}[label]
            print(f"  - {label_name}æ ‡ç­¾: {stats['count']} ä¸ª, å¹³å‡æ”¶ç›Š: {stats['mean']:.4f}")
    
    return tbm_labels, quality_analysis


def demo_cusum_events():
    """æ¼”ç¤ºCUSUMäº‹ä»¶è¿‡æ»¤å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ” æ¼”ç¤º 1.1: CUSUMäº‹ä»¶è¿‡æ»¤å™¨")
    print("=" * 60)
    
    # åˆ›å»ºå¸¦è¶‹åŠ¿çš„ä»·æ ¼æ•°æ®
    np.random.seed(42)
    n_periods = 500
    
    # åŠ å…¥ä¸€äº›è¶‹åŠ¿å’Œçªå‘äº‹ä»¶
    base_returns = np.random.normal(0.0001, 0.01, n_periods)
    # åœ¨ç‰¹å®šä½ç½®æ·»åŠ çªå‘äº‹ä»¶
    base_returns[100:110] += 0.005   # ä¸Šæ¶¨è¶‹åŠ¿
    base_returns[200:210] -= 0.008   # ä¸‹è·Œè¶‹åŠ¿
    base_returns[350:360] += 0.003   # å°å¹…ä¸Šæ¶¨
    
    prices = pd.Series(100 * np.exp(np.cumsum(base_returns)))
    
    # åˆå§‹åŒ–TBMæ ‡ç­¾å™¨
    tbm_labeler = TripleBarrierLabeler(
        profit_factor=1.5,
        loss_factor=1.0,
        max_holding_period=30
    )
    
    # ä½¿ç”¨CUSUMè¿‡æ»¤å™¨ç”Ÿæˆäº‹ä»¶
    cusum_events = tbm_labeler.generate_cusum_events(prices, threshold=0.01)
    
    print(f"CUSUMäº‹ä»¶è¿‡æ»¤ç»“æœ:")
    print(f"  - æ€»ä»·æ ¼ç‚¹æ•°: {len(prices)}")
    print(f"  - CUSUMè§¦å‘äº‹ä»¶: {len(cusum_events)}")
    print(f"  - äº‹ä»¶å¯†åº¦: {len(cusum_events)/len(prices)*100:.2f}%")
    
    if len(cusum_events) > 0:
        print(f"  - äº‹ä»¶ä½ç½®ç¤ºä¾‹: {cusum_events[:10]}")
    
    return cusum_events


def demo_advanced_features():
    """æ¼”ç¤ºé«˜çº§ç‰¹å¾å·¥ç¨‹"""
    print("\n" + "=" * 80)
    print("ğŸ”§ æ¼”ç¤º 3: é«˜çº§ç‰¹å¾å·¥ç¨‹")
    print("=" * 80)
    
    # åˆ›å»ºç¤ºä¾‹OHLCVæ•°æ®
    np.random.seed(42)
    n_periods = 500
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®
    base_price = 100
    returns = np.random.normal(0.0001, 0.02, n_periods)
    close = base_price * np.exp(np.cumsum(returns))
    
    # è½¬æ¢ä¸ºpandas Seriesä»¥ä¾¿ä½¿ç”¨shiftæ–¹æ³•
    close = pd.Series(close)
    
    # ç”ŸæˆOHLCæ•°æ®
    high = close * (1 + np.abs(np.random.normal(0, 0.01, n_periods)))
    low = close * (1 - np.abs(np.random.normal(0, 0.01, n_periods)))
    open_price = close.shift(1).fillna(close.iloc[0])
    
    # ç”Ÿæˆæˆäº¤é‡æ•°æ®
    volume = np.random.lognormal(10, 0.5, n_periods)
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame({
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': volume
    })
    
    print(f"åˆ›å»ºç¤ºä¾‹OHLCVæ•°æ®: {len(df)} ä¸ªæ•°æ®ç‚¹")
    print(f"ä»·æ ¼èŒƒå›´: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
    
    # åˆå§‹åŒ–é«˜çº§ç‰¹å¾å·¥ç¨‹å™¨
    feature_engineer = AdvancedFeatureEngineer(
        volatility_windows=[5, 10, 20],
        microstructure_windows=[5, 15],
        statistical_windows=[10, 20, 50]
    )
    
    # æ„å»ºæ‰€æœ‰ç‰¹å¾
    features_df = feature_engineer.build_all_features(df)
    
    print(f"\nğŸ“Š ç‰¹å¾å·¥ç¨‹ç»“æœ:")
    print(f"  - åŸå§‹ç‰¹å¾: {len(df.columns)}")
    print(f"  - æ€»ç‰¹å¾æ•°: {len(features_df.columns)}")
    print(f"  - æ–°å¢ç‰¹å¾: {len(features_df.columns) - len(df.columns)}")
    
    # ç‰¹å¾ç±»åˆ«ç»Ÿè®¡
    feature_categories = {
        'æ³¢åŠ¨ç‡ç‰¹å¾': len([c for c in features_df.columns if 'volatility' in c or 'vol_' in c]),
        'å¾®è§‚ç»“æ„ç‰¹å¾': len([c for c in features_df.columns if any(x in c for x in ['volume', 'vwap', 'shadow', 'liquidity'])]),
        'ç»Ÿè®¡ç‰¹å¾': len([c for c in features_df.columns if any(x in c for x in ['skewness', 'kurtosis', 'quantile', 'momentum'])]),
        'æŠ€æœ¯æŒ‡æ ‡': len([c for c in features_df.columns if any(x in c for x in ['rsi', 'macd', 'bb_', 'adx'])]),
        'åˆ†å½¢ç‰¹å¾': len([c for c in features_df.columns if any(x in c for x in ['frac_diff', 'hurst', 'dfa'])])
    }
    
    print(f"\nğŸ“ˆ ç‰¹å¾ç±»åˆ«åˆ†å¸ƒ:")
    for category, count in feature_categories.items():
        if count > 0:
            print(f"  - {category}: {count} ä¸ª")
    
    # æ˜¾ç¤ºä¸€äº›é‡è¦ç‰¹å¾çš„ç»Ÿè®¡
    important_features = [c for c in features_df.columns if any(x in c for x in ['volatility_simple', 'rsi', 'macd'])][:5]
    if important_features:
        print(f"\nğŸ¯ é‡è¦ç‰¹å¾ç»Ÿè®¡:")
        for feature in important_features:
            values = features_df[feature].dropna()
            if len(values) > 0:
                print(f"  - {feature}: å‡å€¼={values.mean():.4f}, æ ‡å‡†å·®={values.std():.4f}")
    
    return features_df


def demo_model_evaluation():
    """æ¼”ç¤ºé«˜çº§æ¨¡å‹è¯„ä¼°ï¼ˆéœ€è¦æ¨¡æ‹Ÿæ•°æ®ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¼”ç¤º 4: é«˜çº§æ¨¡å‹è¯„ä¼°")
    print("=" * 80)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿçš„åˆ†ç±»ç»“æœç”¨äºæ¼”ç¤º
    np.random.seed(42)
    n_samples = 1000
    
    # æ¨¡æ‹ŸçœŸå®æ ‡ç­¾ï¼ˆä¸‰åˆ†ç±»ï¼š0=ä¸‹è·Œ, 1=ä¸­æ€§, 2=ä¸Šæ¶¨ï¼‰
    y_true = np.random.choice([0, 1, 2], size=n_samples, p=[0.3, 0.4, 0.3])
    
    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœï¼ˆæœ‰ä¸€å®šå‡†ç¡®æ€§ï¼‰
    y_pred = y_true.copy()
    # æ·»åŠ ä¸€äº›é¢„æµ‹é”™è¯¯
    error_indices = np.random.choice(n_samples, size=int(n_samples * 0.25), replace=False)
    y_pred[error_indices] = np.random.choice([0, 1, 2], size=len(error_indices))
    
    # æ¨¡æ‹Ÿé¢„æµ‹æ¦‚ç‡
    y_proba = np.random.dirichlet([1, 1, 1], size=n_samples)
    # è®©æ¦‚ç‡ä¸é¢„æµ‹æ ‡ç­¾æ›´ä¸€è‡´
    for i in range(n_samples):
        y_proba[i, y_pred[i]] = max(y_proba[i, y_pred[i]], 0.6)
        y_proba[i] = y_proba[i] / y_proba[i].sum()  # é‡æ–°æ ‡å‡†åŒ–
    
    print(f"åˆ›å»ºæ¨¡æ‹Ÿåˆ†ç±»ç»“æœ: {n_samples} ä¸ªæ ·æœ¬")
    print(f"çœŸå®æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_true)}")
    print(f"é¢„æµ‹æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_pred)}")
    
    # åˆå§‹åŒ–æ¨¡å‹è¯„ä¼°å™¨
    evaluator = AdvancedModelEvaluator(save_plots=False)  # ä¸ä¿å­˜å›¾è¡¨ç”¨äºæ¼”ç¤º
    
    # åˆ†ç±»æ€§èƒ½è¯„ä¼°
    class_names = ['ä¸‹è·Œ', 'ä¸­æ€§', 'ä¸Šæ¶¨']
    classification_results = evaluator.evaluate_classification_performance(
        y_true, y_pred, y_proba, class_names
    )
    
    # ç”Ÿæˆæ¨¡æ‹Ÿä¿¡å·å’Œæ”¶ç›Šç‡ç”¨äºä¿¡å·è´¨é‡åˆ†æ
    signals = np.random.normal(0, 0.5, n_samples)
    returns = np.random.normal(0.001, 0.02, n_samples)
    # è®©ä¿¡å·ä¸æ”¶ç›Šæœ‰ä¸€å®šç›¸å…³æ€§
    signals = signals + 0.3 * returns
    
    print(f"\nç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“ä¿¡å·å’Œæ”¶ç›Šç‡...")
    
    # ä¿¡å·è´¨é‡åˆ†æ
    signal_quality_results = evaluator.analyze_signal_quality(signals, returns)
    
    # å›æµ‹æ€§èƒ½åˆ†æ
    backtesting_results = evaluator.analyze_backtesting_performance(
        signals, returns, initial_capital=100000
    )
    
    print(f"\nğŸ“ˆ è¯„ä¼°ç»“æœæ‘˜è¦:")
    print(f"âœ… åˆ†ç±»æ€§èƒ½:")
    print(f"  - å‡†ç¡®ç‡: {classification_results['accuracy']:.4f}")
    print(f"  - F1åˆ†æ•°: {classification_results['f1_macro']:.4f}")
    print(f"  - MCC: {classification_results['matthews_corrcoef']:.4f}")
    
    print(f"\nâœ… ä¿¡å·è´¨é‡:")
    stats = signal_quality_results['signal_stats']
    print(f"  - ä¿¡å·å‡å€¼: {stats['mean']:.4f}")
    print(f"  - ä¿¡å·æ ‡å‡†å·®: {stats['std']:.4f}")
    if 'signal_return_correlation' in signal_quality_results:
        print(f"  - ä¿¡å·-æ”¶ç›Šç›¸å…³æ€§: {signal_quality_results['signal_return_correlation']:.4f}")
    
    print(f"\nâœ… å›æµ‹æ€§èƒ½:")
    returns_data = backtesting_results['returns']
    risk_data = backtesting_results['risk']
    ratios_data = backtesting_results['ratios']
    
    print(f"  - æ€»æ”¶ç›Šç‡: {returns_data['total_return']:.2%}")
    print(f"  - å¹´åŒ–æ”¶ç›Šç‡: {returns_data['annual_return']:.2%}")
    print(f"  - å¹´åŒ–æ³¢åŠ¨ç‡: {risk_data['volatility']:.2%}")
    print(f"  - å¤æ™®æ¯”ç‡: {ratios_data['sharpe_ratio']:.4f}")
    print(f"  - æœ€å¤§å›æ’¤: {risk_data['max_drawdown']:.2%}")
    
    evaluation_results = {
        'classification': classification_results,
        'signal_quality': signal_quality_results,
        'backtesting': backtesting_results
    }
    
    return evaluation_results


def demo_meta_labeling():
    """æ¼”ç¤ºå…ƒæ ‡ç­¾æŠ€æœ¯ï¼ˆéœ€è¦é¢„è®­ç»ƒæ¨¡å‹ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ” æ¼”ç¤º 2: å…ƒæ ‡ç­¾æŠ€æœ¯ (Meta-Labeling)")
    print("=" * 80)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„è®­ç»ƒæ¨¡å‹
    config = load_config()
    
    model_path = config.model.model_save_path
    if not os.path.exists(model_path):
        print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒçš„ä¸»æ¨¡å‹")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒæµç¨‹ï¼špython demo_tbm_meta_labeling.py --mode train")
        return None
    
    try:
        # åŠ è½½å¢å¼ºä¿¡å·ç”Ÿæˆå™¨
        generator = EnhancedSignalGenerator(config)
        
        # å°è¯•åŠ è½½æ¨¡å‹
        generator.load_models()
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå…ƒæ ‡ç­¾æŠ€æœ¯å¯ç”¨")
        
        # å¦‚æœæœ‰æµ‹è¯•æ•°æ®ï¼Œç”Ÿæˆä¸€äº›ç¤ºä¾‹ä¿¡å·
        data_path = config.model.data_path
        if os.path.exists(data_path):
            print(f"\nä½¿ç”¨æ•°æ®æ–‡ä»¶è¿›è¡Œæ¼”ç¤º: {data_path}")
            
            # åŠ è½½å°‘é‡æ•°æ®è¿›è¡Œæ¼”ç¤º
            df = pd.read_parquet(data_path)
            demo_data = df.tail(200)  # ä½¿ç”¨æœ€å200è¡Œæ•°æ®
            
            # æ‰¹é‡æ¨ç†
            results = generator.batch_inference(demo_data)
            
            print(f"\nğŸ“ˆ å…ƒæ ‡ç­¾å¢å¼ºä¿¡å·æ¼”ç¤º:")
            print(f"  - å¤„ç†æ ·æœ¬æ•°: {results['sample_count']}")
            print(f"  - ç‰¹å¾ç»´åº¦: {results['feature_count']}")
            
            # æ˜¾ç¤ºä¿¡å·ç»Ÿè®¡
            decisions = results['decisions']
            print(f"  - ç”Ÿæˆäº¤æ˜“å†³ç­–: {len(decisions)}")
            print(f"  - ä¹°å…¥ä¿¡å·: {(decisions['action'] == 'BUY').sum()}")
            print(f"  - å–å‡ºä¿¡å·: {(decisions['action'] == 'SELL').sum()}")
            print(f"  - æŒæœ‰ä¿¡å·: {(decisions['action'] == 'HOLD').sum()}")
            print(f"  - é«˜ç½®ä¿¡åº¦å†³ç­–: {decisions['high_confidence'].sum()}")
            
            return results
        
    except Exception as e:
        print(f"âŒ å…ƒæ ‡ç­¾æ¼”ç¤ºå¤±è´¥: {e}")
        print("å¯èƒ½éœ€è¦å…ˆè®­ç»ƒå…ƒæ ‡ç­¾æ¨¡å‹")
        return None


def run_training_pipeline():
    """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿"""
    print("=" * 80)
    print("ğŸš€ è¿è¡Œå®Œæ•´è®­ç»ƒæµæ°´çº¿")
    print("=" * 80)
    
    try:
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        config = load_config()
        data_path = config.model.data_path
        
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            print("è¯·ç¡®ä¿æœ‰å¯ç”¨çš„ç‰¹å¾æ•°æ®æ–‡ä»¶")
            return False
        
        # åˆ›å»ºè®­ç»ƒæµæ°´çº¿
        pipeline = AdvancedTrainingPipeline(config)
        
        # è¿è¡Œå®Œæ•´æµç¨‹
        print("\nå¼€å§‹è®­ç»ƒæµç¨‹...")
        results = pipeline.run_complete_pipeline()
        
        if results['status'] == 'success':
            print("\nğŸ‰ è®­ç»ƒæµæ°´çº¿æˆåŠŸå®Œæˆ!")
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            if 'primary_model' in results:
                accuracy = results['primary_model']['best_val_accuracy']
                print(f"âœ… ä¸»æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {accuracy:.2f}%")
            
            if 'meta_labeling' in results and results['meta_labeling']:
                auc = results['meta_labeling'].get('validation_auc', 0)
                print(f"âœ… å…ƒæ ‡ç­¾æ¨¡å‹AUC: {auc:.4f}")
            
            if 'signals' in results and results['signals']:
                stats = results['signals']['statistics']
                print(f"âœ… é«˜ç½®ä¿¡åº¦ä¿¡å·æ¯”ä¾‹: {stats['high_conf_signal_ratio']:.4f}")
            
            return True
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒæµæ°´çº¿å¼‚å¸¸: {e}")
        return False


def run_inference_demo():
    """è¿è¡Œæ¨ç†æ¼”ç¤º"""
    print("=" * 80)
    print("ğŸ“ˆ è¿è¡Œå¢å¼ºä¿¡å·æ¨ç†æ¼”ç¤º")
    print("=" * 80)
    
    try:
        config = load_config()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
        if not os.path.exists(config.model.model_save_path):
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            print("è¯·å…ˆè¿è¡Œ: python demo_tbm_meta_labeling.py --mode train")
            return False
        
        # åŠ è½½å¢å¼ºä¿¡å·ç”Ÿæˆå™¨
        generator = EnhancedSignalGenerator(config)
        generator.load_models()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        data_path = config.model.data_path
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return False
        
        print(f"åŠ è½½æ•°æ®: {data_path}")
        df = pd.read_parquet(data_path)
        
        # ä½¿ç”¨æœ€åçš„æ•°æ®è¿›è¡Œæ¨ç†æ¼”ç¤º
        test_data = df.tail(500)
        print(f"ä½¿ç”¨æœ€æ–° {len(test_data)} è¡Œæ•°æ®è¿›è¡Œæ¨ç†")
        
        # æ‰¹é‡æ¨ç†
        results = generator.batch_inference(test_data)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š æ¨ç†ç»“æœæ‘˜è¦:")
        print(f"  - å¤„ç†æ ·æœ¬æ•°: {results['sample_count']}")
        print(f"  - ç‰¹å¾ç»´åº¦: {results['feature_count']}")
        
        decisions = results['decisions']
        signals = results['signals']
        
        # ä¿¡å·ç»Ÿè®¡
        print(f"\nğŸ¯ äº¤æ˜“ä¿¡å·ç»Ÿè®¡:")
        action_counts = decisions['action'].value_counts()
        for action, count in action_counts.items():
            percentage = count / len(decisions) * 100
            print(f"  - {action}: {count} ({percentage:.1f}%)")
        
        # ä¿¡å·è´¨é‡ç»Ÿè®¡
        high_conf_mask = decisions['high_confidence']
        high_conf_decisions = decisions[high_conf_mask]
        
        print(f"\nâ­ é«˜ç½®ä¿¡åº¦ä¿¡å·åˆ†æ:")
        print(f"  - é«˜ç½®ä¿¡åº¦ä¿¡å·æ•°: {len(high_conf_decisions)}")
        print(f"  - é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: {len(high_conf_decisions)/len(decisions)*100:.2f}%")
        
        if len(high_conf_decisions) > 0:
            high_conf_actions = high_conf_decisions['action'].value_counts()
            print(f"  - é«˜ç½®ä¿¡åº¦äº¤æ˜“åˆ†å¸ƒ:")
            for action, count in high_conf_actions.items():
                print(f"    {action}: {count}")
        
        # ä¿å­˜ç»“æœ
        save_path = 'results/inference_demo_results.pkl'
        generator.save_inference_results(results, save_path)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def run_rl_training_pipeline():
    """è¿è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæµæ°´çº¿"""
    if not RL_AVAILABLE:
        print("âš ï¸ å¼ºåŒ–å­¦ä¹ æ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ï¼Œæ— æ³•è¿è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚")
        return False

    print("=" * 80)
    print("ğŸš€ è¿è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæµæ°´çº¿")
    print("=" * 80)
    
    try:
        config = load_config()
        data_path = config.model.data_path
        
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            print("è¯·ç¡®ä¿æœ‰å¯ç”¨çš„å¼ºåŒ–å­¦ä¹ æ•°æ®æ–‡ä»¶")
            return False
        
        # åˆ›å»ºå¼ºåŒ–å­¦ä¹ è®­ç»ƒæµæ°´çº¿
        pipeline = RLTrainingPipeline(config)
        
        # è¿è¡Œå®Œæ•´æµç¨‹
        print("\nå¼€å§‹å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹...")
        results = pipeline.run_complete_pipeline()
        
        if results['status'] == 'success':
            print("\nğŸ‰ å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµæ°´çº¿æˆåŠŸå®Œæˆ!")
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            if 'actor_critic' in results:
                print(f"âœ… Actor-Criticæ¨¡å‹è®­ç»ƒæˆåŠŸã€‚")
                print(f"  - è®­ç»ƒè½®æ•°: {results['actor_critic']['epochs']}")
                print(f"  - æ€»å¥–åŠ±: {results['actor_critic']['total_reward']:.2f}")
                print(f"  - å¹³å‡å¥–åŠ±: {results['actor_critic']['mean_reward']:.4f}")
                print(f"  - æœ€ç»ˆç­–ç•¥ç†µ: {results['actor_critic']['final_policy_entropy']:.4f}")
            
            if 'mdp_env' in results and results['mdp_env']:
                print(f"âœ… MDPç¯å¢ƒè®­ç»ƒæˆåŠŸã€‚")
                print(f"  - ç¯å¢ƒæ­¥æ•°: {results['mdp_env']['total_steps']}")
                print(f"  - å¹³å‡æ­¥é•¿: {results['mdp_env']['mean_step_length']:.2f}")
                print(f"  - å¹³å‡å¥–åŠ±: {results['mdp_env']['mean_reward']:.4f}")
            
            if 'backtester' in results and results['backtester']:
                print(f"âœ… å›æµ‹å™¨è®­ç»ƒæˆåŠŸã€‚")
                print(f"  - å›æµ‹æ€»æ­¥æ•°: {results['backtester']['total_steps']}")
                print(f"  - å¹³å‡æ­¥é•¿: {results['backtester']['mean_step_length']:.2f}")
                print(f"  - å¹³å‡å¥–åŠ±: {results['backtester']['mean_reward']:.4f}")
            
            return True
        else:
            print(f"âŒ å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
            
    except Exception as e:
        print(f"âŒ å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµæ°´çº¿å¼‚å¸¸: {e}")
        return False


def run_rl_demo():
    """è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤º"""
    if not RL_AVAILABLE:
        print("âš ï¸ å¼ºåŒ–å­¦ä¹ æ¨¡å—æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ï¼Œæ— æ³•è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤ºã€‚")
        return False

    print("=" * 80)
    print("ğŸ“ˆ è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤º")
    print("=" * 80)
    
    try:
        config = load_config()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
        if not os.path.exists(config.model.model_save_path):
            print("âŒ æœªæ‰¾åˆ°å¼ºåŒ–å­¦ä¹ æ¨¡å‹")
            print("è¯·å…ˆè¿è¡Œ: python demo_tbm_meta_labeling.py --mode rl_train")
            return False
        
        # åŠ è½½å¼ºåŒ–å­¦ä¹ æ¨¡å‹
        agent = ActorCriticAgent(config)
        agent.load_models()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        data_path = config.model.data_path
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return False
        
        print(f"åŠ è½½æ•°æ®: {data_path}")
        df = pd.read_parquet(data_path)
        
        # åˆ›å»ºMDPç¯å¢ƒ
        mdp_env = TradingMDPEnvironment(df, config)
        
        # è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤º
        print("\nå¼€å§‹å¼ºåŒ–å­¦ä¹ æ¼”ç¤º...")
        backtester = RobustBacktester(mdp_env, agent, config)
        results = backtester.run_episode(initial_capital=100000)
        
        print(f"\nğŸ“Š å¼ºåŒ–å­¦ä¹ æ¼”ç¤ºç»“æœ:")
        print(f"  - æ€»æ­¥æ•°: {results['total_steps']}")
        print(f"  - æ€»å¥–åŠ±: {results['total_reward']:.2f}")
        print(f"  - å¹³å‡å¥–åŠ±: {results['mean_reward']:.4f}")
        print(f"  - æœ€ç»ˆç­–ç•¥ç†µ: {results['final_policy_entropy']:.4f}")
        
        # å›æµ‹æ€§èƒ½åˆ†æ
        backtesting_results = backtester.analyze_backtesting_performance(
            results['actions'], results['rewards'], initial_capital=100000
        )
        
        print(f"\nğŸ“ˆ å¼ºåŒ–å­¦ä¹ å›æµ‹æ€§èƒ½:")
        returns_data = backtesting_results['returns']
        risk_data = backtesting_results['risk']
        ratios_data = backtesting_results['ratios']
        
        print(f"  - æ€»æ”¶ç›Šç‡: {returns_data['total_return']:.2%}")
        print(f"  - å¹´åŒ–æ”¶ç›Šç‡: {returns_data['annual_return']:.2%}")
        print(f"  - å¹´åŒ–æ³¢åŠ¨ç‡: {risk_data['volatility']:.2%}")
        print(f"  - å¤æ™®æ¯”ç‡: {ratios_data['sharpe_ratio']:.4f}")
        print(f"  - æœ€å¤§å›æ’¤: {risk_data['max_drawdown']:.2%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¼ºåŒ–å­¦ä¹ æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def run_complete_demo():
    """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
    print("ğŸ¬ å¼€å§‹å®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    
    print("\nç¬¬ä¸€éƒ¨åˆ†ï¼šç†è®ºå’ŒæŠ€æœ¯æ¼”ç¤ºï¼ˆæ— éœ€è®­ç»ƒæ•°æ®ï¼‰")
    
    # 1. TBMæ ‡ç­¾æ¼”ç¤º
    tbm_results = demo_tbm_labeling()
    
    # 2. CUSUMäº‹ä»¶è¿‡æ»¤æ¼”ç¤º
    cusum_results = demo_cusum_events()
    
    # 3. é«˜çº§ç‰¹å¾å·¥ç¨‹æ¼”ç¤º
    features_results = demo_advanced_features()
    
    # 4. é«˜çº§æ¨¡å‹è¯„ä¼°æ¼”ç¤º
    evaluation_results = demo_model_evaluation()
    
    print("\nç¬¬äºŒéƒ¨åˆ†ï¼šå®é™…æ¨¡å‹æ¼”ç¤ºï¼ˆéœ€è¦è®­ç»ƒæ•°æ®ï¼‰")
    
    # 5. å…ƒæ ‡ç­¾æ¼”ç¤ºï¼ˆå¦‚æœæœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼‰
    meta_results = demo_meta_labeling()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ å®Œæ•´æ¼”ç¤ºç»“æŸ")
    print("=" * 80)
    
    print("\nğŸ“ æ¼”ç¤ºæ€»ç»“:")
    print("âœ… ä¸‰åˆ†ç±»æ ‡ç­¾æ³•ï¼šå±•ç¤ºäº†åŠ¨æ€è¾¹ç•Œå’Œè·¯å¾„ä¾èµ–çš„æ ‡ç­¾ç”Ÿæˆ")
    print("âœ… CUSUMè¿‡æ»¤å™¨ï¼šå±•ç¤ºäº†ç»“æ„æ€§å˜åŒ–çš„äº‹ä»¶æ£€æµ‹")
    print("âœ… é«˜çº§ç‰¹å¾å·¥ç¨‹ï¼šå±•ç¤ºäº†å¤šç§ç±»å‹çš„é«˜çº§é‡‘èç‰¹å¾æ„å»º")
    print("âœ… é«˜çº§æ¨¡å‹è¯„ä¼°ï¼šå±•ç¤ºäº†åˆ†ç±»æ€§èƒ½ã€ä¿¡å·è´¨é‡å’Œå›æµ‹åˆ†æ")
    
    if meta_results is not None:
        print("âœ… å…ƒæ ‡ç­¾æŠ€æœ¯ï¼šå±•ç¤ºäº†ä¸¤é˜¶æ®µå­¦ä¹ æ¡†æ¶çš„ä¿¡å·å¢å¼º")
    else:
        print("âš ï¸ å…ƒæ ‡ç­¾æŠ€æœ¯ï¼šéœ€è¦å…ˆè®­ç»ƒæ¨¡å‹æ‰èƒ½å®Œæ•´æ¼”ç¤º")
    
    print(f"\nğŸ“Š æŠ€æœ¯ç‰¹æ€§ç»Ÿè®¡:")
    if tbm_results:
        print(f"  - TBMæ ‡ç­¾æ•°é‡: {len(tbm_results[0])}")
    if cusum_results:
        print(f"  - CUSUMäº‹ä»¶æ•°: {len(cusum_results)}")
    if features_results is not None:
        print(f"  - ç”Ÿæˆç‰¹å¾æ•°: {len(features_results.columns)}")
    if evaluation_results:
        acc = evaluation_results['classification']['accuracy']
        print(f"  - æ¼”ç¤ºæ¨¡å‹å‡†ç¡®ç‡: {acc:.2%}")
    
    print("\nğŸ“– ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. å¦‚éœ€è®­ç»ƒæ¨¡å‹ï¼špython demo_tbm_meta_labeling.py --mode train")
    print("2. å¦‚éœ€æ¨ç†æ¼”ç¤ºï¼špython demo_tbm_meta_labeling.py --mode inference")
    print("3. æŸ¥çœ‹è¯¦ç»†å®ç°ï¼š")
    print("   - TBMå®ç°ï¼šdata_processing/features/triple_barrier_labeling.py")
    print("   - é«˜çº§ç‰¹å¾ï¼šdata_processing/features/advanced_features.py")
    print("   - å…ƒæ ‡ç­¾å®ç°ï¼šstrategy/training/meta_labeling.py")
    print("   - æ¨¡å‹è¯„ä¼°ï¼šstrategy/analysis/advanced_model_evaluation.py")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä¸‰åˆ†ç±»æ ‡ç­¾æ³•å’Œå…ƒæ ‡ç­¾æŠ€æœ¯æ¼”ç¤º",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
    # è¿è¡Œå®Œæ•´æ¼”ç¤ºï¼ˆç†è®º+å®è·µï¼‰
    python demo_tbm_meta_labeling.py --mode demo
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨TBMæ ‡ç­¾å’Œå…ƒæ ‡ç­¾æŠ€æœ¯ï¼‰
    python demo_tbm_meta_labeling.py --mode train
    
    # è¿è¡Œæ¨ç†æ¼”ç¤º
    python demo_tbm_meta_labeling.py --mode inference
    
    # è¿è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
    python demo_tbm_meta_labeling.py --mode rl_train
    
    # è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤º
    python demo_tbm_meta_labeling.py --mode rl_demo
        """
    )
    
    parser.add_argument(
        '--mode', 
        choices=['demo', 'train', 'inference', 'rl_demo', 'rl_train'],
        default='demo',
        help='è¿è¡Œæ¨¡å¼ï¼šdemo=å®Œæ•´æ¼”ç¤º, train=è®­ç»ƒæ¨¡å‹, inference=æ¨ç†æ¼”ç¤º, rl_demo=å¼ºåŒ–å­¦ä¹ æ¼”ç¤º, rl_train=å¼ºåŒ–å­¦ä¹ è®­ç»ƒ'
    )
    
    parser.add_argument(
        '--data_path',
        type=str,
        help='æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ ä¸‰åˆ†ç±»æ ‡ç­¾æ³•å’Œå…ƒæ ‡ç­¾æŠ€æœ¯æ¼”ç¤º")
    print("=" * 80)
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if args.data_path:
        print(f"æ•°æ®è·¯å¾„: {args.data_path}")
        # è¿™é‡Œå¯ä»¥æ›´æ–°é…ç½®ä¸­çš„æ•°æ®è·¯å¾„
    
    print("=" * 80)
    
    try:
        if args.mode == 'demo':
            run_complete_demo()
        elif args.mode == 'train':
            success = run_training_pipeline()
            if success:
                print("\nâœ… è®­ç»ƒå®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œæ¨ç†æ¼”ç¤ºï¼š")
                print("python demo_tbm_meta_labeling.py --mode inference")
        elif args.mode == 'inference':
            success = run_inference_demo()
            if success:
                print("\nâœ… æ¨ç†æ¼”ç¤ºå®Œæˆï¼")
        elif args.mode == 'rl_train':
            success = run_rl_training_pipeline()
            if success:
                print("\nâœ… å¼ºåŒ–å­¦ä¹ è®­ç»ƒå®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œå¼ºåŒ–å­¦ä¹ æ¼”ç¤ºï¼š")
                print("python demo_tbm_meta_labeling.py --mode rl_demo")
        elif args.mode == 'rl_demo':
            success = run_rl_demo()
            if success:
                print("\nâœ… å¼ºåŒ–å­¦ä¹ æ¼”ç¤ºå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main() 